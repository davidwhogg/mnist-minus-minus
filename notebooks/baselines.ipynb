{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SOVH_6gOtPM"
   },
   "source": [
    "# MNIST-minus-minus: Train and test baselines\n",
    "\n",
    "## Authors\n",
    "- **David W Hogg** (NYU) (Flatiron)\n",
    "- **Soledad Villar** (JHU)\n",
    "\n",
    "## To-Do / Bugs:\n",
    "- Possibly switch the MLP to a CNN?\n",
    "- How to assess / check that the model is doing a good job where it appears to be?\n",
    " - For example, can we find the orientations of 6s and 9s in a pure 6-9++ sample?\n",
    "- Need to apply learned transformations to the test data after learning the group elements.\n",
    "- Figure out how to run on MNIST+4 labels.\n",
    " - Maybe 4 classifications on each of the 4 labels separately?\n",
    "- Figure out how to run on MNIST+Inf group elements.\n",
    " - Maybe just switch to a regression with 4 outputs?\n",
    "- Maybe implement a \"reasoning\" system that learns orientation first, applies it, and then does image contents?\n",
    "\n",
    "## Notes\n",
    "- We got some of the sample code from the (excellent) *jax* examples documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pe_qAE4zOq9D"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap, random\n",
    "from jax.scipy.special import logsumexp\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import time\n",
    "import os\n",
    "import ssl\n",
    "from urllib.request import urlopen\n",
    "from shutil import copyfileobj\n",
    "import gzip\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in all MNIST++ datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "baseurl = \"https://cosmo.nyu.edu/hogg/research/2023/04/17/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_read_pickle(filename, clobber=False):\n",
    "    if clobber or not os.path.isfile(filename):\n",
    "        with urlopen(baseurl + filename) as in_stream, open(filename, 'wb') as out_file:\n",
    "            copyfileobj(in_stream, out_file)\n",
    "    with gzip.open(filename, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read SixtyNine++\n",
    "(X_train69, M_train69, y_train69), (X_test69, M_test69, y_test69) = get_and_read_pickle(\"SixtyNine++.pkl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Fashion++\n",
    "(X_trainf, M_trainf, y_trainf), (X_testf, M_testf, y_testf) = get_and_read_pickle(\"Fashion++.pkl.gz\")\n",
    "print(X_trainf.shape, M_trainf.shape, y_trainf.shape,\n",
    "      X_testf.shape,  M_testf.shape,  y_testf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read MNIST+4\n",
    "(X_train4, M_train4, y_train4), (X_test4, M_test4, y_test4) = get_and_read_pickle(\"MNIST+4.pkl.gz\")\n",
    "print(X_train4.shape, M_train4.shape, y_train4.shape,\n",
    "      X_test4.shape,  M_test4.shape,  y_test4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at label statistics for MNIST+4\n",
    "sstr = set(y_train4)\n",
    "print(\"total number of labels missing from the training set:\", 10000 - len(sstr))\n",
    "sste = set(y_test4)\n",
    "print(\"total number of labels missing from the test set:\", 10000 - len(sste))\n",
    "i = 0\n",
    "for q in sste:\n",
    "    if q not in sstr:\n",
    "        i += 1\n",
    "        print(i, \"label\", q, \"is in the test set but not in the training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pfy5ygvrsBNt"
   },
   "outputs": [],
   "source": [
    "# Read MNIST+9\n",
    "(X_train9, M_train9, y_train9), (X_test9, M_test9, y_test9) = get_and_read_pickle(\"MNIST+9.pkl.gz\")\n",
    "print(X_train9.shape, M_train9.shape, y_train9.shape,\n",
    "      X_test9.shape,  M_test9.shape,  y_test9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yl_dvhGMYMko"
   },
   "outputs": [],
   "source": [
    "# Read MNIST+Inf\n",
    "(X_trainInf, M_trainInf, y_trainInf), (X_testInf, M_testInf, y_testInf) = get_and_read_pickle(\"MNIST+Inf.pkl.gz\")\n",
    "print(X_trainInf.shape, M_trainInf.shape, y_trainInf.shape,\n",
    "      X_testInf.shape,  M_testInf.shape,  y_testInf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up MLP model\n",
    "*Note:* Most of this code is copied from the *jax* documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "  return jnp.maximum(0, x)\n",
    "\n",
    "def predict(params, image):\n",
    "  # per-example predictions\n",
    "  activations = image\n",
    "  for w, b in params[:-1]:\n",
    "    outputs = jnp.dot(w, activations) + b\n",
    "    activations = relu(outputs)\n",
    "  \n",
    "  final_w, final_b = params[-1]\n",
    "  logits = jnp.dot(final_w, activations) + final_b\n",
    "  return logits - logsumexp(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to randomly initialize weights and biases\n",
    "# for a dense neural network layer\n",
    "def random_layer_params(m, n, key, scale=1e-2):\n",
    "  w_key, b_key = random.split(key)\n",
    "  return scale * random.normal(w_key, (n, m)), scale * random.normal(b_key, (n,))\n",
    "\n",
    "# Initialize all layers for a fully-connected neural network with sizes \"sizes\"\n",
    "def init_network_params(sizes, key):\n",
    "  keys = random.split(key, len(sizes))\n",
    "  return [random_layer_params(m, n, k) for m, n, k in zip(sizes[:-1], sizes[1:], keys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(X, label_list, dtype=jnp.float32):\n",
    "    \"\"\"Create a one-hot encoding\"\"\"\n",
    "    foo = jnp.array([x == label_list for x in X], dtype)\n",
    "    while len(foo.shape) > 2:\n",
    "        foo = foo.all(axis=-1)\n",
    "    return foo\n",
    "\n",
    "# Make a batched version of the `predict` function\n",
    "batched_predict = vmap(predict, in_axes=(None, 0))\n",
    "\n",
    "def accuracy(params, images, targets):\n",
    "    target_class = jnp.argmax(targets, axis=1)\n",
    "    predicted_class = jnp.argmax(batched_predict(params, images), axis=1)\n",
    "    return jnp.mean(predicted_class == target_class)\n",
    "\n",
    "def loss(params, images, targets):\n",
    "    preds = batched_predict(params, images)\n",
    "    return -jnp.mean(preds * targets)\n",
    "\n",
    "@jit\n",
    "def update(params, x, y, step_size):\n",
    "    grads = grad(loss)(params, x, y)\n",
    "    return [(w - step_size * dw, b - step_size * db)\n",
    "              for (w, b), (dw, db) in zip(params, grads)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure TF does not see GPU and grab all GPU memory.\n",
    "tf.config.set_visible_devices([], device_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some parameters\n",
    "def train_and_test(X_train, y_train, X_test, y_test):\n",
    "    assert len(X_train) == len(y_train)\n",
    "    assert len(X_test) == len(y_test)\n",
    "\n",
    "    num_pixels = X_train[0].shape[0] * X_train[0].shape[1]\n",
    "    label_list = np.unique(y_train, axis=0)\n",
    "    num_labels = len(label_list)\n",
    "    layer_sizes = [num_pixels, 512, 512, num_labels] # MAGIC\n",
    "    step_size = 0.01 # MAGIC\n",
    "    num_epochs =  8  # MAGIC\n",
    "    batch_size = 128 # MAGIC\n",
    "    n_targets = num_labels\n",
    "    print(\"Found {} distinct labels, and input images with {} pixels\".format(num_labels, num_pixels))\n",
    "    print(\"The labels are {}\".format(label_list))\n",
    "    \n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    train_images = jnp.reshape(X_train, (len(X_train), num_pixels))\n",
    "    train_labels = one_hot(y_train, label_list)\n",
    "    test_images = jnp.reshape(X_test, (len(X_test), num_pixels))\n",
    "    test_labels = one_hot(y_test, label_list)\n",
    "    print(\"Now train_labels is {}\".format(train_labels.shape))\n",
    "    print(\"Their sums are {}\".format(np.sum(train_labels, axis=0)))\n",
    "\n",
    "    params = init_network_params(layer_sizes, random.PRNGKey(0))\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        for x, y in tfds.as_numpy(train_dataset.batch(batch_size).prefetch(1)):\n",
    "            x = jnp.reshape(x, (len(x), num_pixels))\n",
    "            y = one_hot(y, label_list)\n",
    "            params = update(params, x, y, step_size)\n",
    "        epoch_time = time.time() - start_time\n",
    "\n",
    "        train_acc = accuracy(params, train_images, train_labels)\n",
    "        test_acc = accuracy(params, test_images, test_labels)\n",
    "        print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
    "        print(\"Training set accuracy {}\".format(train_acc))\n",
    "        print(\"Test set accuracy {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test MLP model on the 5 easy cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Challenge nobody asked for\n",
    "train_and_test(X_train69, M_train69.reshape(-1, 4),\n",
    "               X_test69,  M_test69.reshape(-1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Challenge nobody asked for\n",
    "train_and_test(X_train69, y_train69,\n",
    "               X_test69,  y_test69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 1\n",
    "train_and_test(X_trainf, y_trainf, X_testf, y_testf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 2\n",
    "train_and_test(X_train4, M_train4.reshape(-1, 4),\n",
    "               X_test4,  M_test4.reshape(-1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 4\n",
    "train_and_test(X_train9, M_train9.reshape(-1, 4),\n",
    "               X_test9,  M_test9.reshape(-1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 5\n",
    "train_and_test(X_train9, y_train9, X_test9, y_test9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 7\n",
    "train_and_test(X_trainInf, y_trainInf, X_testInf, y_testInf)# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now do the MNIST+4 hard case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbd: Challenge 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now do the MNIST+Inf hard case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbd: Challenge 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPIYrE61nDcLVCM+1Hb2Xuq",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
